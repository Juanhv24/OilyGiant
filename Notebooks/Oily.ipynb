{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8547ee8e",
            "metadata": {},
            "source": [
                "# 1. Packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "9453f7d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import mean_squared_error"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ba71b68",
            "metadata": {},
            "source": [
                "# 2. Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "528a39e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_0 = pd.read_csv(r'C:\\Users\\juand\\OneDrive\\Escritorio\\TripleTen\\OilyGiant\\Datasets\\geo_data_0.csv')\n",
                "geo_1 = pd.read_csv(r'C:\\Users\\juand\\OneDrive\\Escritorio\\TripleTen\\OilyGiant\\Datasets\\geo_data_1.csv')\n",
                "geo_2 = pd.read_csv(r'C:\\Users\\juand\\OneDrive\\Escritorio\\TripleTen\\OilyGiant\\Datasets\\geo_data_2.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_exploration_header",
            "metadata": {},
            "source": [
                "# 3. Data Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "bd3eaa53",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 100000 entries, 0 to 99999\n",
                        "Data columns (total 5 columns):\n",
                        " #   Column   Non-Null Count   Dtype  \n",
                        "---  ------   --------------   -----  \n",
                        " 0   id       100000 non-null  object \n",
                        " 1   f0       100000 non-null  float64\n",
                        " 2   f1       100000 non-null  float64\n",
                        " 3   f2       100000 non-null  float64\n",
                        " 4   product  100000 non-null  float64\n",
                        "dtypes: float64(4), object(1)\n",
                        "memory usage: 3.8+ MB\n",
                        "None\n",
                        "\n",
                        "\n",
                        "      id        f0        f1        f2     product\n",
                        "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
                        "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
                        "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
                        "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
                        "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n"
                    ]
                }
            ],
            "source": [
                "print (geo_0.info())\n",
                "print ('\\n')\n",
                "print (geo_0.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "ea4b1096",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 100000 entries, 0 to 99999\n",
                        "Data columns (total 5 columns):\n",
                        " #   Column   Non-Null Count   Dtype  \n",
                        "---  ------   --------------   -----  \n",
                        " 0   id       100000 non-null  object \n",
                        " 1   f0       100000 non-null  float64\n",
                        " 2   f1       100000 non-null  float64\n",
                        " 3   f2       100000 non-null  float64\n",
                        " 4   product  100000 non-null  float64\n",
                        "dtypes: float64(4), object(1)\n",
                        "memory usage: 3.8+ MB\n",
                        "None\n",
                        "\n",
                        "\n",
                        "      id         f0         f1        f2     product\n",
                        "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
                        "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
                        "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
                        "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
                        "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n"
                    ]
                }
            ],
            "source": [
                "print (geo_1.info())\n",
                "print ('\\n')\n",
                "print (geo_1.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1d8f6ebd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 100000 entries, 0 to 99999\n",
                        "Data columns (total 5 columns):\n",
                        " #   Column   Non-Null Count   Dtype  \n",
                        "---  ------   --------------   -----  \n",
                        " 0   id       100000 non-null  object \n",
                        " 1   f0       100000 non-null  float64\n",
                        " 2   f1       100000 non-null  float64\n",
                        " 3   f2       100000 non-null  float64\n",
                        " 4   product  100000 non-null  float64\n",
                        "dtypes: float64(4), object(1)\n",
                        "memory usage: 3.8+ MB\n",
                        "None\n",
                        "\n",
                        "\n",
                        "      id        f0        f1        f2     product\n",
                        "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
                        "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
                        "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
                        "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
                        "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
                    ]
                }
            ],
            "source": [
                "print (geo_2.info())\n",
                "print ('\\n')\n",
                "print (geo_2.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model_training_header",
            "metadata": {},
            "source": [
                "# 4. Model Training and Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "3bcf2a99",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "---Region 0---\n",
                        "RMSE: 37.5794217150813\n",
                        "Mean Volume: 92.59\n",
                        "---Region 1---\n",
                        "RMSE: 0.8930992867756166\n",
                        "Mean Volume: 68.73\n",
                        "---Region 2---\n",
                        "RMSE: 40.02970873393434\n",
                        "Mean Volume: 94.97\n"
                    ]
                }
            ],
            "source": [
                "def train_valid (df, region_name): # Define a function to train and validate the model for a given region\n",
                "    # Split the data into features and target\n",
                "    X = df.drop (['id', 'product'], axis=1)\n",
                "    y = df['product']\n",
                "\n",
                "    # Split the data into train and validation sets\n",
                "    # Split data into 75% train and 25% validation\n",
                "    X_train, X_valid, y_train, y_valid = train_test_split (X, y, test_size=0.25, random_state=12345)\n",
                "\n",
                "    # Train the model \n",
                "    model = LinearRegression() \n",
                "    model.fit (X_train, y_train) # Train the model using the training data\n",
                "    predictions = model.predict (X_valid) # Make predictions on the validation set\n",
                "\n",
                "    # Calculate metrics \n",
                "    rmse = mean_squared_error (y_valid, predictions)**0.5 # Calculate Root Mean Squared Error\n",
                "    mean_volume = predictions.mean() \n",
                "    \n",
                "    print (f'---{region_name}---')\n",
                "    print (f'RMSE: {rmse}')\n",
                "    print (f'Mean Volume: {mean_volume:.2f}')\n",
                "\n",
                "    # Return correct answers and predictions \n",
                "    return y_valid, predictions\n",
                "\n",
                "# Execute function for each region \n",
                "target_0, preds_0 = train_valid (geo_0, 'Region 0')\n",
                "target_1, preds_1 = train_valid (geo_1, 'Region 1')\n",
                "target_2, preds_2 = train_valid (geo_2, 'Region 2')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "911df612",
            "metadata": {},
            "source": [
                "**Results Analysis**\n",
                "\n",
                "- **Region 0:** \n",
                "\n",
                "    The average volume is high, but with a large margin of error (37.58). This means the model is not very accurate for this region. Sometimes it predicts volumes that are too high or too low.\n",
                "\n",
                "- **Region 1:** \n",
                "\n",
                "    This data point is key. Although the average volume is lower (68 vs. 92), the error is minuscule. The model is extremely accurate here. What it predicts is almost exactly what actually happens. This reduces the risk enormously.\n",
                "\n",
                "- **Region 2:** \n",
                "\n",
                "    Similar to Region 0. It has the highest average volume, but also the highest error. It is the most \"risky\" and uncertain region."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "profit_prep_header",
            "metadata": {},
            "source": [
                "# 5. Profit Calculation Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "abdb5536",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cost per well:500,000\n",
                        "Needed volume:111.11 units\n",
                        "\n",
                        "---Comparison with regional average---\n",
                        "Region 0(Average: 92.59) vs Needed (111.11) -> Deficit:-18.52\n",
                        "Region 1(Average: 68.73) vs Needed (111.11) -> Deficit:-42.38\n",
                        "Region 2(Average: 94.97) vs Needed (111.11) -> Deficit:-16.14\n"
                    ]
                }
            ],
            "source": [
                "# Project variables\n",
                "budget = 100_000_000\n",
                "income_per_unit = 4_500\n",
                "wells = 200\n",
                "\n",
                "# 1. How much to open a well?\n",
                "cost_per_well = budget / wells\n",
                "\n",
                "# 2. How much oil does the well have to produce to recover the investment?\n",
                "needed_volume = cost_per_well / income_per_unit # Calculate volume needed to break even\n",
                "\n",
                "print (f'Cost per well:{cost_per_well:,.0f}')\n",
                "print (f'Needed volume:{needed_volume:,.2f} units')\n",
                "\n",
                "# 3. Comparison with what actually exists in the regions.abs\n",
                "print ('\\n---Comparison with regional average---')\n",
                "print (f'Region 0(Average: 92.59) vs Needed (111.11) -> Deficit:{92.59 - needed_volume:,.2f}')\n",
                "print (f'Region 1(Average: 68.73) vs Needed (111.11) -> Deficit:{68.73 - needed_volume:,.2f}')\n",
                "print (f'Region 2(Average: 94.97) vs Needed (111.11) -> Deficit:{94.97 - needed_volume:,.2f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d38d043f",
            "metadata": {},
            "source": [
                "- **Required volume (Break-even): 111.11 units.**\n",
                "\n",
                "- **The problem:** No region has that average.\n",
                "\n",
                "Region 0: 92.59 (Short of ~18 units)\n",
                "\n",
                "Region 1: 68.73 (Short of ~42 units)\n",
                "\n",
                "Region 2: 94.96 (Short of ~16 units)\n",
                "\n",
                "If we selected wells at random, this business would be a disaster, because the average reserves are insufficient to cover costs (111.11). This necessitates the use of Machine Learning. The regional \"average\" is not sufficient; we need the model to act like a sniper and select only those 200 specific points that are significantly above the average."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "profit_calc_header",
            "metadata": {},
            "source": [
                "# 6. Profit Calculation for Top 200 Wells"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "058bbf6c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "---Potencial profit (Top 200 wells)---\n",
                        "Region 0:\n",
                        "  Total Volume: 29601.84 units\n",
                        "  Potential Profit: $33.21 Millions USD\n",
                        "Region 1:\n",
                        "  Total Volume: 27589.08 units\n",
                        "  Potential Profit: $24.15 Millions USD\n",
                        "Region 2:\n",
                        "  Total Volume: 28245.22 units\n",
                        "  Potential Profit: $27.10 Millions USD\n"
                    ]
                }
            ],
            "source": [
                "def calculate_profits(target, predictions, count): # Define a function to calculate potential profits for top 'count' wells\n",
                "    predictions = pd.Series(predictions)\n",
                "\n",
                "    # 1. Sort predictions from highest to lowest\n",
                "    sorted_predictions = predictions.sort_values (ascending=False)\n",
                "\n",
                "    t_reset = target.reset_index(drop=True)\n",
                "    p_reset = predictions.reset_index(drop=True)\n",
                "    \n",
                "    # 2. Sort the predictions\n",
                "    sorted_predictions = p_reset.sort_values(ascending=False)\n",
                "    \n",
                "    # 3. Select the indices of the best ones\n",
                "    selected_indices = sorted_predictions.index[:count] # Select indices of the top predictions\n",
                "    \n",
                "    # 4. Use those indices to get the real volume\n",
                "    # This works now because selected_indices are small numbers (0..499)\n",
                "    real_volume = t_reset.iloc[selected_indices] # Extract actual volumes using the selected indices\n",
                "    total_volume = real_volume.sum()\n",
                "    \n",
                "    # 5. Calculate profit\n",
                "    profit = (total_volume * 4_500) - 100_000_000 # Calculate profit: Revenue - Budget\n",
                "    \n",
                "    return total_volume, profit\n",
                "    \n",
                "regions = ['Region 0', 'Region 1', 'Region 2']\n",
                "\n",
                "data_pairs = [(target_0, preds_0), (target_1, preds_1), (target_2, preds_2)]\n",
                "\n",
                "print ('---Potential profit (Top 200 wells)---')\n",
                "for i, (target, preds) in enumerate(data_pairs):\n",
                "    vol, profit = calculate_profits(target, preds, 200)\n",
                "    print(f\"{regions[i]}:\")\n",
                "    print(f\"  Total Volume: {vol:.2f} units\")\n",
                "    print(f\"  Potential Profit: ${profit/1_000_000:.2f} Millions USD\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c1aaf4b",
            "metadata": {},
            "source": [
                "**Preliminary Analysis:** At first glance, Region 0 appears to be the most lucrative option, surpassing Region 1 by almost $9 million. This suggests that Region 0 contains wells with exceptionally high reserves (outliers or \"jackpots\") that raise the profit ceiling.\n",
                "\n",
                "**However, this conclusion is misleading and should not be taken as definitive.** This calculation assumes we have access to explore all wells to select only the best (\"cherry-picking\"). In operational reality, we will be limited to exploring only a random sample of 500 points. This is where the high variance and model error (high RMSE) of Regions 0 and 2 work against us: if our random sample doesn't include those \"super wells,\" the risk of losses is high.\n",
                "\n",
                "Conversely, **Region 1**, although showing a lower profit ceiling here ($24M), has a near-perfect predictive model (RMSE 0.89). This suggests that its performance will be much more stable and secure when we move to realistic exploration conditions."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "risk_assessment_header",
            "metadata": {},
            "source": [
                "# 7. Risk Assessment and Bootstrap Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "b53b5e37",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Resultados Finales de Riesgo ---\n",
                        "Region 0:\n",
                        "  Promedio: $3.96 M\n",
                        "  Riesgo: 6.9%\n",
                        "  IC (95%): $-1.11 M a $9.10 M\n",
                        "--------------------\n",
                        "Region 1:\n",
                        "  Promedio: $4.61 M\n",
                        "  Riesgo: 0.7%\n",
                        "  IC (95%): $0.78 M a $8.63 M\n",
                        "--------------------\n",
                        "Region 2:\n",
                        "  Promedio: $3.93 M\n",
                        "  Riesgo: 6.5%\n",
                        "  IC (95%): $-1.12 M a $9.35 M\n",
                        "--------------------\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# Make sure target_0, pred_0, etc. are loaded previously\n",
                "\n",
                "state = np.random.RandomState(12345)\n",
                "\n",
                "def calculate_profits(target, predictions, count):\n",
                "    # Function corrected to avoid index errors\n",
                "    t_reset = target.reset_index(drop=True)\n",
                "    p_reset = pd.Series(predictions).reset_index(drop=True)\n",
                "    \n",
                "    sorted_predictions = p_reset.sort_values(ascending=False)\n",
                "    selected_indices = sorted_predictions.index[:count]\n",
                "    \n",
                "    real_volume = t_reset.iloc[selected_indices]\n",
                "    total_volume = real_volume.sum()\n",
                "    \n",
                "    return total_volume, (total_volume * 4_500) - 100_000_000\n",
                "\n",
                "def bootstrap_analysis(target, predictions): # Define bootstrap analysis to estimate risk and profit distribution\n",
                "    values = []\n",
                "    # Reset indices BEFORE entering the loop for general cleanup\n",
                "    target = target.reset_index(drop=True)\n",
                "    predictions = pd.Series(predictions).reset_index(drop=True)\n",
                "    \n",
                "    for i in range(1000): # Perform 1000 bootstrap iterations\n",
                "        # Sampling\n",
                "        target_subsample = target.sample(n=500, replace=True, random_state=state) # Sample 500 points with replacement to simulate exploration\n",
                "        # Use indices to get corresponding predictions\n",
                "        probs_subsample = predictions[target_subsample.index]\n",
                "        \n",
                "        # Since calculate_profits now does internal reset_index, this is safe\n",
                "        _, profit = calculate_profits(target_subsample, probs_subsample, 200) # Calculate profit for the best 200 wells in this sample\n",
                "        values.append(profit)\n",
                "        \n",
                "    values = pd.Series(values)\n",
                "    mean_profit = values.mean()\n",
                "    risk = (values < 0).mean() * 100 # Calculate risk as the percentage of negative profits\n",
                "    lower = values.quantile(0.025) # 2.5th percentile for 95% Confidence Interval\n",
                "    upper = values.quantile(0.975) # 97.5th percentile for 95% Confidence Interval\n",
                "    \n",
                "    return mean_profit, risk, lower, upper\n",
                "\n",
                "# Execution\n",
                "regions = ['Region 0', 'Region 1', 'Region 2']\n",
                "data_pairs = [(target_0, preds_0), (target_1, preds_1), (target_2, preds_2)]\n",
                "\n",
                "print(\"--- Final Risk Results ---\")\n",
                "for i, (tgt, pred) in enumerate(data_pairs):\n",
                "    mean, risk, lower, upper = bootstrap_analysis(tgt, pred)\n",
                "    print(f\"{regions[i]}:\")\n",
                "    print(f\"  Mean: ${mean/1_000_000:.2f} M\")\n",
                "    print(f\"  Risk: {risk:.1f}%\")\n",
                "    print(f\"  CI (95%): ${lower/1_000_000:.2f} M to ${upper/1_000_000:.2f} M\")\n",
                "    print(\"-\" * 20)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d835bf73",
            "metadata": {},
            "source": [
                "## **General conclusion**\n",
                "\n",
                "\n",
                "After analyzing the risks and profits using the bootstrapping technique (1,000 samples), we have reached the following conclusions:\n",
                "\n",
                "1. **Risk Evaluation**:\n",
                "\n",
                "    - **Region 0**: Risk = 6.0% (Too high).\n",
                "    - **Region 2**: Risk = 6.2% (Too high).\n",
                "    - **Region 1**: Risk = 0.3% (Acceptable, < 2.5%).\n",
                "\n",
                "2. **Profitability**:\n",
                "\n",
                "    - **Region 1** not only has the lowest risk but also the highest average profit (~$5.18 Million USD).\n",
                "\n",
                "3. **Justification**:\n",
                "\n",
                "    Although Region 1 has lower average reserves per well overall, the Linear Regression model works exceptionally well there (RMSE 0.89). This high precision allows us to identify profitable wells with high certainty, minimizing the risk of drilling dry wells.\n",
                "\n",
                "**Recommendation:** We should proceed with the development of Region 1. It is the only region that meets the business requirement of keeping the risk of loss below 2.5%, while maximizing the expected return."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "oily",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
